{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first presentation was going to answer the question, does healthy equate to happy?  We had great ideas in regards to the data we wanted to collect, as the first go around on the optional data sets and API's appeared to have the data we were looking to measure. Upon further investigatioin,  the step counts, physical stats and gender information was a bit harder to pull from an API than we thought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we are now working to see if we can use data provided by the census API, a Kaggle data series that contained over 2,000 Chipotle stores as well as a sample set of data from Kaggle regarding other fast food locations, to see if we can predict what factors may influence a Chipotle location. Originally we had a few different years of information, but because we could not obtain the 2019 census data, we had enough with 2018 we used that year as our basis.\n",
    "\n",
    "Kaggle data: https://www.kaggle.com/jeffreybraun/chipotle-locations\n",
    "Sample data from other fast food locations: https://www.kaggle.com/datafiniti/fast-food-restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we pulled and cleaned all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from census import Census\n",
    "\n",
    "# Census API Key\n",
    "from config import api_key\n",
    "c = Census(api_key, year=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Census Search to retrieve data on all zip codes (2017 ACS5 Census)\n",
    "# See: https://github.com/CommerceDataService/census-wrapper for library documentation\n",
    "# See: https://gist.github.com/afhaque/60558290d6efd892351c4b64e5c01e9b for labels\n",
    "census_data = c.acs5.get((\"NAME\", \"B19013_001E\", \"B01003_001E\", \"B01002_001E\",\n",
    "                          \"B19301_001E\",\n",
    "                          \"B17001_002E\"), {'for': 'zip code tabulation area:*'})\n",
    "\n",
    "# Convert to DataFrame\n",
    "census_pd = pd.DataFrame(census_data)\n",
    "\n",
    "# Column Reordering\n",
    "census_pd = census_pd.rename(columns={\"B01003_001E\": \"Population\",\n",
    "                                      \"B01002_001E\": \"Median Age\",\n",
    "                                      \"B19013_001E\": \"Household Income\",\n",
    "                                      \"B19301_001E\": \"Per Capita Income\",\n",
    "                                      \"B17001_002E\": \"Poverty Count\",\n",
    "                                      \"NAME\": \"Name\", \"zip code tabulation area\": \"Zipcode\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final DataFrame\n",
    "census_pd = census_pd[[\"Zipcode\", \"Population\", \"Median Age\", \"Household Income\",\n",
    "                       \"Per Capita Income\", \"Poverty Count\"]]\n",
    "\n",
    "# Visualize\n",
    "print(len(census_pd))\n",
    "census_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Poverty Rate at the end\n",
    "census_pd[\"Poverty Rate\"]=census_pd[\"Poverty Count\"]*100/ census_pd[\"Population\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all NaN data\n",
    "census_pd.dropna(subset=['Household Income', 'Per Capita Income', 'Poverty Rate'], inplace=True)\n",
    "census_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need latitude and longitude information for a map later referenced.  A pull from the google places API was not working, and I did not want to run up my API account so I used the referenced link to obtain the information I could then add into the census data. https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/table/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Latitude and Longitude to census data for later use\n",
    "latlong =\"Resources/us-zip-code-latitude-and-longitude.csv\"\n",
    "# Read files into Pandas DF\n",
    "latlong= pd.read_csv(latlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(latlong))\n",
    "latlong.head()\n",
    "latlong.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There was an additional space in the Zipcode series from the latitidue file so it had to be renamed prior to merging\n",
    "latlong=latlong.rename(columns={'Zipcode ': 'Zipcode'})\n",
    "latlong.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with census data\n",
    "clean_2018_census_pd = pd.merge(census_pd, latlong,on='Zipcode')\n",
    "clean_2018_census_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made all Zipcodes integers instead of floats\n",
    "clean_2018_census_pd['Zipcode']= clean_2018_census_pd['Zipcode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for easier merging with restaurant data\n",
    "clean_2018_census_pd = clean_2018_census_pd[['Zipcode','Latitude', 'Longitude','Population', 'Median Age', 'Household Income', 'Per Capita Income', 'Poverty Count', 'Poverty Rate']]\n",
    "clean_2018_census_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV\n",
    "clean_2018_census_pd.to_csv(\"Resources/census_data_clean_2018.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restaurant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all restaurant first and clean\n",
    "fast_food_restaurants_2018 = \"../Resources/Fast_Food_Restaurants_2018.csv\"\n",
    "# Read files into Pandas DF\n",
    "Rest_2018 = pd.read_csv(fast_food_restaurants_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns we will not need\n",
    "Rest_2018=Rest_2018.drop(['id','sourceURLs','websites'], axis =1)\n",
    "Rest_2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize/rename columns\n",
    "Rest_2018 = Rest_2018.rename(columns={'name':'Name', 'address': 'Address', 'city': 'City', 'country': 'Country', 'latitude': 'Latitude', 'longitude':'Longitude', 'postalCode': 'Zip Code',\\\n",
    "                                     'province': 'State'})\n",
    "Rest_2018 = Rest_2018[['Name', 'Address', 'City','State', 'Zip Code','Country', 'Latitude', 'Longitude']]\n",
    "Rest_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique names in list and sort alphabetically to assist with cleaning\n",
    "names = Rest_2018['Name'].unique()\n",
    "names.sort()\n",
    "print(len(names))\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all locations that were duplicate but had different capitalizations, punctuations, etc\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({\"Arby's - Closed\":\"Arby's\",'Arbys': \"Arby's\", \"Auntie Anne's\": \"Auntie Anne's Pretzels\",\"Baker's Drive Thru\":\"Baker's Drive-thru\",\"Ben and Jerry's\": \"Ben & Jerry's\",'Bob Evans Restaurant':'Bob Evans',\"Bojangles' Famous Chicken 'n Biscuits\": 'Bojangles', 'Burger King¬Æ': 'Burger King','Capri Italian Restaurant':'Capri Restaurant',\"Carl's Jr.\":\"Carl's Jr\",\"Carl's Jr. / Green Burrito\":\"Carl's Jr\",\"Carl's Jr / Green Burrito\":\"Carl's Jr\",'Caseys Carry Out Pizza':\"Casey's General Store\",\"Charley's Grilled Subs\":'Charleys Philly Steaks',\"Checker's Pizza\":'Checkers','Chick-fil-A':'Chick-Fil-A', 'Chipotle':'Chipotle Mexican Grill','Dairy Queen (Treat Only)':'Dairy Queen','Dunkin Donuts':\"Dunkin' Donuts\",'Five Guys Burgers Fries':'Five Guys', 'Five Guys Burgers And Fries':'Five Guys',\"Foster's Freeze\":'Fosters Freeze', \"Hardee's\":'Hardees',\"Hardee's / Red Burrito\":'Hardees', \"Hardee's/red Burrito\":'Hardees','Jack in the Box':'Jack In The Box', 'Jack in the Box -':'Jack In The Box'})\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({\"Jimmy John's\":'Jimmy Johns','KFC - Kentucky Fried Chicken':'KFC','KFC/AW':'KFC','KFC/Long John Silvers':'KFC', 'KFC/Taco Bell':'KFC'})\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({\"Little Caesar's Pizza\":'Little Caesars', 'Little Caesars Pizza':'Little Caesars',\"Long John Silver's / AW\" 'Long John Silvers':\"Long John Silver's\",'Long John Silvers / A&W':\"Long John Silver's\",'Mc Donalds':\"McDonald's\",\"McDonald's of Rolesville\":\"McDonald's\",'McDonalds':\"McDonald's\",\"McDonalds's\":\"McDonald's\",\"Mcdonald's\":\"McDonald's\",'Mcdonalds':\"McDonald's\",'Mcdonalds Whitehouse':\"McDonald's\"})\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({'Panda Express Innovation Kitchen':'Panda Express' ,'PepperJax Grill':'Pepperjax Grill',\"Popeye's Louisiana Kitchen\":'Popeyes','Popeyes Chicken & Biscuits':'Popeyes','Popeyes Chicken Biscuits':'Popeyes','Popeyes Louisiana Kitchen':'Popeyes'})\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({'QDOBA Mexican Eats':'Qdoba Mexican Grill', 'Qdoba Mexican Eats':'Qdoba Mexican Grill', \"Quizno's\": 'Quiznos', 'Quiznos Sub':'Quiznos',\"Raising Cane's\":'Raising Canes', \"Raising Cane's Chicken Fingers\":'Raising Canes'})\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({\"Rally's Hamburgers\":\"Rally's\", 'Rallys':\"Rally's\",'Roma Pizza':'Romas Pizza','SONIC Drive In': 'SONIC Drive-In', 'SUBWAY¬Æ':'SUBWAY'})\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({'Sonic':'SONIC Drive-In', \"Sonic America's Drive-In\":'SONIC Drive-In','Sonic Drive In':'SONIC Drive-In','Sonic Drive in':'SONIC Drive-In','Sonic Drive-In':'SONIC Drive-In',\"Steak 'n Shake\":'Steak N Shake','Taco Bell / KFC':'Taco Bell' ,'Taco Bell/KFC':'Taco Bell','Taco Bell/Pizza Hut':'Taco Bell'})\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({ 'Wienerschitzel':'Wienerschnitzel','Wingstop Restaurant':'Wingstop',\"Wolf's Dairy Queen\" :'Dairy Queen',\"Zaxby's Chicken Fingers & Buffalo Wings\": \"Zaxby's\",'b.good':'B.GOOD', 'A&W/Long John Silvers':\"Long John Silver's\"})\n",
    "# After going through team decided to rename Pizza Hut, Taco Bell and KFC to YUM Brands\n",
    "Rest_2018['Name'] = Rest_2018['Name'].replace({'Pizza Hut': 'YUM Brands', 'KFC': 'YUM Brands','Taco Bell': 'YUM Brands'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Rest_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove locations that are not food related 'Walmart Supercenter''T-Mobile''Hilton Boston Logan Airport''7-Eleven'\n",
    "# https://thispointer.com/python-pandas-how-to-drop-rows-in-dataframe-by-conditions-on-column-values/\n",
    "indexNames= Rest_2018[(Rest_2018['Name']=='Walmart Supercenter')].index\n",
    "Rest_2018.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames= Rest_2018[(Rest_2018['Name']=='T-Mobile')].index\n",
    "Rest_2018.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames= Rest_2018[(Rest_2018['Name']=='Hilton Boston Logan Airport')].index\n",
    "Rest_2018.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames= Rest_2018[(Rest_2018['Name']=='7-Eleven')].index\n",
    "Rest_2018.drop(indexNames, inplace=True)\n",
    "print(len(Rest_2018))\n",
    "Rest_2018['Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of entries for each location\n",
    "Rest_2018['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all locations that have less than 50 entries\n",
    "# https://www.thetopsites.net/article/58467286.shtml\n",
    "threshold = 50\n",
    "clean_rest_2018 = Rest_2018[Rest_2018.groupby('Name')['Name'].transform('count')>threshold].copy()\n",
    "print(len(clean_rest_2018))\n",
    "clean_rest_2018['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv as this is clean data incase anything happens while added in other informatoin\n",
    "clean_rest_2018.to_csv('../Resources/clean_rest_2018.csv', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine with chipotle csv\n",
    "# first read get file then read into pandas DF\n",
    "Chipotle_stores = \"../Resources/chipotle_stores.csv\"\n",
    "chipotle = pd.read_csv(Chipotle_stores)\n",
    "chipotle.head(2)\n",
    "print(len(chipotle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rest_2018.head(2)\n",
    "print(len(clean_rest_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 2 restaurant dataframes. Used concat to just add the other restaurant data underneath the chipotle information\n",
    "all_rest_df = pd.concat([chipotle, clean_rest_2018])\n",
    "print(len(all_rest_df))\n",
    "all_rest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add census data to right of all rest data(printed head to get column names)\n",
    "census2_2018.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next three cells were from my tutor \n",
    "https://github.com/ealong/Springboard-Capstone1/blob/master/capstone1-wrangling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converted to string because restaurant data information was listed as string and could not merge properly\n",
    "# Adjusted series name to allow proper merge as well\n",
    "# Confirm number of zip codes with less than 5 digits\n",
    "census2_2018['Zipcode'] = census2_2018['Zipcode'].astype(str)\n",
    "census_2018 = census2_2018.rename(columns={'Zipcode': 'Zip Code'})\n",
    "census_2018_badzip= census_2018[census_2018['Zip Code'].str.len()<5]\n",
    "print(census_2018_badzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Research confirms that for the cities and states with zip codesless than 5 digits, the zip codes begin with 0.\n",
    "#Excel truncates the leading zero. (#e.g. 06001 becomes 6001 in Excel) \n",
    "\n",
    "def format_postal_codes(row):\n",
    "    zipcode= row['Zip Code']\n",
    "    return zipcode[:5].zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix zip codes to have 5 digits\n",
    "census_2018['Zip Code'] = census_2018.apply(format_postal_codes, axis=1)\n",
    "\n",
    "census_2018_badzip = census_2018[census3_2018['Zip Code'].str.len()<5]\n",
    "print(census_2018_badzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add census data to right of all rest data\n",
    "all_rest_new = pd.merge(all_rest_df,census_2018, on=\"Zip Code\", how='left')\n",
    "all_rest_new.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove and rename extra lat/long columns\n",
    "all_rest_new = all_rest_new.rename(columns={'Latitude_x': 'Latitude', 'Longitude_x':'Longitude'})\n",
    "all_rest_df = all_rest_new[['Name', 'Address', 'City','State', 'Zip Code','Country', 'Latitude', 'Longitude','Population', 'Median Age', 'Household Income','Per Capita Income', 'Poverty Count', 'Poverty Rate']]\n",
    "all_rest_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV for others to use\n",
    "all_rest_df.to_csv(\"Resources/All_rest_2018.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
